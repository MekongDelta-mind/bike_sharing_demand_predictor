{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rides_previous_672_hour</th>\n",
       "      <th>rides_previous_671_hour</th>\n",
       "      <th>rides_previous_670_hour</th>\n",
       "      <th>rides_previous_669_hour</th>\n",
       "      <th>rides_previous_668_hour</th>\n",
       "      <th>rides_previous_667_hour</th>\n",
       "      <th>rides_previous_666_hour</th>\n",
       "      <th>rides_previous_665_hour</th>\n",
       "      <th>rides_previous_664_hour</th>\n",
       "      <th>rides_previous_663_hour</th>\n",
       "      <th>...</th>\n",
       "      <th>rides_next_27_hour</th>\n",
       "      <th>rides_next_28_hour</th>\n",
       "      <th>rides_next_29_hour</th>\n",
       "      <th>rides_next_30_hour</th>\n",
       "      <th>rides_next_31_hour</th>\n",
       "      <th>rides_next_32_hour</th>\n",
       "      <th>rides_next_33_hour</th>\n",
       "      <th>rides_next_34_hour</th>\n",
       "      <th>rides_next_35_hour</th>\n",
       "      <th>rides_next_36_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111211</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111212</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111213</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111214</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111215</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111216 rows × 710 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rides_previous_672_hour  rides_previous_671_hour  \\\n",
       "0                           1.0                      1.0   \n",
       "1                           1.0                      0.0   \n",
       "2                           0.0                      1.0   \n",
       "3                           4.0                      2.0   \n",
       "4                           0.0                      0.0   \n",
       "...                         ...                      ...   \n",
       "111211                      0.0                      0.0   \n",
       "111212                      0.0                      0.0   \n",
       "111213                      2.0                      0.0   \n",
       "111214                      0.0                      0.0   \n",
       "111215                      0.0                      0.0   \n",
       "\n",
       "        rides_previous_670_hour  rides_previous_669_hour  \\\n",
       "0                           1.0                      0.0   \n",
       "1                           1.0                      0.0   \n",
       "2                           2.0                      0.0   \n",
       "3                           2.0                      1.0   \n",
       "4                           1.0                      0.0   \n",
       "...                         ...                      ...   \n",
       "111211                      1.0                      0.0   \n",
       "111212                      0.0                      0.0   \n",
       "111213                      0.0                      0.0   \n",
       "111214                      1.0                      0.0   \n",
       "111215                      0.0                      0.0   \n",
       "\n",
       "        rides_previous_668_hour  rides_previous_667_hour  \\\n",
       "0                           1.0                      0.0   \n",
       "1                           0.0                      0.0   \n",
       "2                           0.0                      2.0   \n",
       "3                           0.0                      0.0   \n",
       "4                           0.0                      0.0   \n",
       "...                         ...                      ...   \n",
       "111211                      0.0                      0.0   \n",
       "111212                      0.0                      0.0   \n",
       "111213                      0.0                      0.0   \n",
       "111214                      0.0                      2.0   \n",
       "111215                      0.0                      2.0   \n",
       "\n",
       "        rides_previous_666_hour  rides_previous_665_hour  \\\n",
       "0                           1.0                      0.0   \n",
       "1                           0.0                      0.0   \n",
       "2                           1.0                      1.0   \n",
       "3                           0.0                      2.0   \n",
       "4                           3.0                      1.0   \n",
       "...                         ...                      ...   \n",
       "111211                      0.0                      0.0   \n",
       "111212                      0.0                      0.0   \n",
       "111213                      0.0                      1.0   \n",
       "111214                      0.0                      1.0   \n",
       "111215                      0.0                      0.0   \n",
       "\n",
       "        rides_previous_664_hour  rides_previous_663_hour  ...  \\\n",
       "0                           0.0                      0.0  ...   \n",
       "1                           0.0                      1.0  ...   \n",
       "2                           1.0                      2.0  ...   \n",
       "3                           1.0                      4.0  ...   \n",
       "4                           3.0                      2.0  ...   \n",
       "...                         ...                      ...  ...   \n",
       "111211                      1.0                      1.0  ...   \n",
       "111212                      0.0                      0.0  ...   \n",
       "111213                      1.0                      1.0  ...   \n",
       "111214                      0.0                      0.0  ...   \n",
       "111215                      1.0                      0.0  ...   \n",
       "\n",
       "        rides_next_27_hour  rides_next_28_hour  rides_next_29_hour  \\\n",
       "0                      1.0                 0.0                 0.0   \n",
       "1                      4.0                 0.0                 0.0   \n",
       "2                      0.0                 0.0                 0.0   \n",
       "3                      2.0                 1.0                 1.0   \n",
       "4                      0.0                 0.0                 0.0   \n",
       "...                    ...                 ...                 ...   \n",
       "111211                 2.0                 0.0                 0.0   \n",
       "111212                 1.0                 0.0                 0.0   \n",
       "111213                 0.0                 0.0                 0.0   \n",
       "111214                 1.0                 0.0                 0.0   \n",
       "111215                 0.0                 0.0                 0.0   \n",
       "\n",
       "        rides_next_30_hour  rides_next_31_hour  rides_next_32_hour  \\\n",
       "0                      1.0                 0.0                 0.0   \n",
       "1                      0.0                 1.0                 2.0   \n",
       "2                      0.0                 2.0                 0.0   \n",
       "3                      0.0                 1.0                 1.0   \n",
       "4                      0.0                 0.0                 0.0   \n",
       "...                    ...                 ...                 ...   \n",
       "111211                 0.0                 0.0                 0.0   \n",
       "111212                 0.0                 0.0                 2.0   \n",
       "111213                 1.0                 0.0                 0.0   \n",
       "111214                 1.0                 0.0                 0.0   \n",
       "111215                 0.0                 0.0                 1.0   \n",
       "\n",
       "        rides_next_33_hour  rides_next_34_hour  rides_next_35_hour  \\\n",
       "0                      2.0                 0.0                 0.0   \n",
       "1                      5.0                 2.0                 2.0   \n",
       "2                      5.0                 4.0                 1.0   \n",
       "3                      7.0                 2.0                 2.0   \n",
       "4                      2.0                 0.0                 1.0   \n",
       "...                    ...                 ...                 ...   \n",
       "111211                 1.0                 0.0                 2.0   \n",
       "111212                 3.0                 0.0                 3.0   \n",
       "111213                 2.0                 0.0                 1.0   \n",
       "111214                 1.0                 2.0                 0.0   \n",
       "111215                 0.0                 0.0                 0.0   \n",
       "\n",
       "        rides_next_36_hour  \n",
       "0                     10.0  \n",
       "1                      2.0  \n",
       "2                      8.0  \n",
       "3                      3.0  \n",
       "4                      4.0  \n",
       "...                    ...  \n",
       "111211                 0.0  \n",
       "111212                 0.0  \n",
       "111213                 1.0  \n",
       "111214                 0.0  \n",
       "111215                 1.0  \n",
       "\n",
       "[111216 rows x 710 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.paths import TRANSFORMED_DATA_DIR\n",
    "\n",
    "df = pd.read_parquet(TRANSFORMED_DATA_DIR / 'tabular_data.parquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape=(40713, 674)\n",
      "y_train.shape=(40713, 36)\n",
      "X_test.shape=(70503, 674)\n",
      "y_test.shape=(70503, 36)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from src.data_split import train_test_split\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_split(\n",
    "    df,\n",
    "    cutoff_date=datetime(2022, 6, 1, 0, 0, 0),\n",
    "    targets_columns_names=[c for c in df.columns if c.startswith('rides_next_')]\n",
    ")\n",
    "\n",
    "print(f'{X_train.shape=}')\n",
    "print(f'{y_train.shape=}')\n",
    "print(f'{X_test.shape=}')\n",
    "print(f'{y_test.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import optuna\n",
    "\n",
    "from src.model import get_pipeline\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Given a set of hyper-parameters, it trains a model and computes an average\n",
    "    validation error based on a TimeSeriesSplit\n",
    "    \"\"\"\n",
    "    # pick hyper-parameters\n",
    "    hyperparams = {\n",
    "        \"metric\": 'mae',\n",
    "        \"verbose\": -1,\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.2, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.2, 1.0),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 3, 100),   \n",
    "    }\n",
    "       \n",
    "    tss = TimeSeriesSplit(n_splits=2)\n",
    "    scores = []\n",
    "    for train_index, val_index in tss.split(X_train):\n",
    "\n",
    "        # split data for training and validation\n",
    "        X_train_, X_val_ = X_train.iloc[train_index, :], X_train.iloc[val_index,:]\n",
    "        y_train_, y_val_ = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        \n",
    "        # train the model\n",
    "        pipeline = get_pipeline(**hyperparams)\n",
    "        pipeline.fit(X_train_, y_train_)\n",
    "        \n",
    "        # evaluate the model\n",
    "        y_pred = pipeline.predict(X_val_)\n",
    "        mae = mean_absolute_error(y_val_, y_pred)\n",
    "\n",
    "        scores.append(mae)\n",
    "   \n",
    "    # Return the mean score\n",
    "    return np.array(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-03 20:03:34,893] A new study created in memory with name: no-name-de8f95d6-914c-40e8-8363-a149c147c401\n",
      "[I 2023-09-03 20:06:07,522] Trial 0 finished with value: 0.5357410238570299 and parameters: {'num_leaves': 110, 'feature_fraction': 0.3159644364620229, 'bagging_fraction': 0.6430982887189218, 'min_child_samples': 59}. Best is trial 0 with value: 0.5357410238570299.\n",
      "[I 2023-09-03 20:09:00,277] Trial 1 finished with value: 0.5355443754329897 and parameters: {'num_leaves': 199, 'feature_fraction': 0.2676844181074463, 'bagging_fraction': 0.8483907851183174, 'min_child_samples': 24}. Best is trial 1 with value: 0.5355443754329897.\n",
      "[I 2023-09-03 20:13:08,872] Trial 2 finished with value: 0.5356831342072661 and parameters: {'num_leaves': 194, 'feature_fraction': 0.7221591738533804, 'bagging_fraction': 0.20992159592618195, 'min_child_samples': 11}. Best is trial 1 with value: 0.5355443754329897.\n",
      "[I 2023-09-03 20:15:21,833] Trial 3 finished with value: 0.535659216021227 and parameters: {'num_leaves': 67, 'feature_fraction': 0.33966552808420386, 'bagging_fraction': 0.30697633989468076, 'min_child_samples': 59}. Best is trial 1 with value: 0.5355443754329897.\n",
      "[I 2023-09-03 20:18:56,543] Trial 4 finished with value: 0.5377303632810835 and parameters: {'num_leaves': 210, 'feature_fraction': 0.4412000769066686, 'bagging_fraction': 0.46043129761292595, 'min_child_samples': 46}. Best is trial 1 with value: 0.5355443754329897.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params={'num_leaves': 199, 'feature_fraction': 0.2676844181074463, 'bagging_fraction': 0.8483907851183174, 'min_child_samples': 24}\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_trial.params\n",
    "print(f'{best_params=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.416796\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.287181\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.155110\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.090856\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.081473\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.187016\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.381770\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.883575\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 1.173090\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 1.010783\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.864834\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 1.042198\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 1.323656\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 1.431435\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 1.433596\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 1.599219\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 1.965318\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 2.263478\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 2.243706\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 1.695699\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 1.398718\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 1.026576\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.697468\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.514062\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.416746\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.286223\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.153857\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.090315\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.080834\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.187606\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.383931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.890600\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 1.182644\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 1.016776\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.868789\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Info] Total Bins 12130\n",
      "[LightGBM] [Info] Number of data points in the train set: 40713, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 1.046521\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;functiontransformer-1&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function average_rides_last_4_weeks at 0x000001D52D424CA0&gt;)),\n",
       "                (&#x27;functiontransformer-2&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function latitude_and_longitude at 0x000001D52E0E4670&gt;)),\n",
       "                (&#x27;temporalfeaturesengineer&#x27;, TemporalFeaturesEngineer()),\n",
       "                (&#x27;multioutputregressor&#x27;,\n",
       "                 MultiOutputRegressor(estimator=LGBMRegressor(bagging_fraction=0.8483907851183174,\n",
       "                                                              feature_fraction=0.2676844181074463,\n",
       "                                                              force_col_wise=True,\n",
       "                                                              min_child_samples=24,\n",
       "                                                              num_leaves=199)))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;functiontransformer-1&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function average_rides_last_4_weeks at 0x000001D52D424CA0&gt;)),\n",
       "                (&#x27;functiontransformer-2&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function latitude_and_longitude at 0x000001D52E0E4670&gt;)),\n",
       "                (&#x27;temporalfeaturesengineer&#x27;, TemporalFeaturesEngineer()),\n",
       "                (&#x27;multioutputregressor&#x27;,\n",
       "                 MultiOutputRegressor(estimator=LGBMRegressor(bagging_fraction=0.8483907851183174,\n",
       "                                                              feature_fraction=0.2676844181074463,\n",
       "                                                              force_col_wise=True,\n",
       "                                                              min_child_samples=24,\n",
       "                                                              num_leaves=199)))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function average_rides_last_4_weeks at 0x000001D52D424CA0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function latitude_and_longitude at 0x000001D52E0E4670&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TemporalFeaturesEngineer</label><div class=\"sk-toggleable__content\"><pre>TemporalFeaturesEngineer()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">multioutputregressor: MultiOutputRegressor</label><div class=\"sk-toggleable__content\"><pre>MultiOutputRegressor(estimator=LGBMRegressor(bagging_fraction=0.8483907851183174,\n",
       "                                             feature_fraction=0.2676844181074463,\n",
       "                                             force_col_wise=True,\n",
       "                                             min_child_samples=24,\n",
       "                                             num_leaves=199))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(bagging_fraction=0.8483907851183174,\n",
       "              feature_fraction=0.2676844181074463, force_col_wise=True,\n",
       "              min_child_samples=24, num_leaves=199)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(bagging_fraction=0.8483907851183174,\n",
       "              feature_fraction=0.2676844181074463, force_col_wise=True,\n",
       "              min_child_samples=24, num_leaves=199)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('functiontransformer-1',\n",
       "                 FunctionTransformer(func=<function average_rides_last_4_weeks at 0x000001D52D424CA0>)),\n",
       "                ('functiontransformer-2',\n",
       "                 FunctionTransformer(func=<function latitude_and_longitude at 0x000001D52E0E4670>)),\n",
       "                ('temporalfeaturesengineer', TemporalFeaturesEngineer()),\n",
       "                ('multioutputregressor',\n",
       "                 MultiOutputRegressor(estimator=LGBMRegressor(bagging_fraction=0.8483907851183174,\n",
       "                                                              feature_fraction=0.2676844181074463,\n",
       "                                                              force_col_wise=True,\n",
       "                                                              min_child_samples=24,\n",
       "                                                              num_leaves=199)))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = get_pipeline(**best_params)\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2676844181074463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2676844181074463\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8483907851183174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8483907851183174\n",
      "test_mae=0.6822\n"
     ]
    }
   ],
   "source": [
    "predictions = pipeline.predict(X_test)\n",
    "test_mae = mean_absolute_error(y_test, predictions)\n",
    "print(f'{test_mae=:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como da algun valor negativo como resultado eliminamos las predicciones negativas y los intervalos negativos reemplazando por cero\n",
    "import numpy as np\n",
    "\n",
    "#Limitar los valores predichos a un mínimo de cero\n",
    "predictions = np.clip(predictions, 0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_mae=0.6811\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "test_mae = mean_absolute_error(y_test, predictions)\n",
    "print(f'{test_mae=:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "x=%{x}<br>y=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "2022-07-17T00:00:00",
          "2022-07-17T01:00:00",
          "2022-07-17T02:00:00",
          "2022-07-17T03:00:00",
          "2022-07-17T04:00:00",
          "2022-07-17T05:00:00",
          "2022-07-17T06:00:00",
          "2022-07-17T07:00:00",
          "2022-07-17T08:00:00",
          "2022-07-17T09:00:00",
          "2022-07-17T10:00:00",
          "2022-07-17T11:00:00",
          "2022-07-17T12:00:00",
          "2022-07-17T13:00:00",
          "2022-07-17T14:00:00",
          "2022-07-17T15:00:00",
          "2022-07-17T16:00:00",
          "2022-07-17T17:00:00",
          "2022-07-17T18:00:00",
          "2022-07-17T19:00:00",
          "2022-07-17T20:00:00",
          "2022-07-17T21:00:00",
          "2022-07-17T22:00:00",
          "2022-07-17T23:00:00",
          "2022-07-18T00:00:00",
          "2022-07-18T01:00:00",
          "2022-07-18T02:00:00",
          "2022-07-18T03:00:00",
          "2022-07-18T04:00:00",
          "2022-07-18T05:00:00",
          "2022-07-18T06:00:00",
          "2022-07-18T07:00:00",
          "2022-07-18T08:00:00",
          "2022-07-18T09:00:00",
          "2022-07-18T10:00:00",
          "2022-07-18T11:00:00",
          "2022-07-18T12:00:00",
          "2022-07-18T13:00:00",
          "2022-07-18T14:00:00",
          "2022-07-18T15:00:00",
          "2022-07-18T16:00:00",
          "2022-07-18T17:00:00",
          "2022-07-18T18:00:00",
          "2022-07-18T19:00:00",
          "2022-07-18T20:00:00",
          "2022-07-18T21:00:00",
          "2022-07-18T22:00:00",
          "2022-07-18T23:00:00",
          "2022-07-19T00:00:00",
          "2022-07-19T01:00:00",
          "2022-07-19T02:00:00",
          "2022-07-19T03:00:00",
          "2022-07-19T04:00:00",
          "2022-07-19T05:00:00",
          "2022-07-19T06:00:00",
          "2022-07-19T07:00:00",
          "2022-07-19T08:00:00",
          "2022-07-19T09:00:00",
          "2022-07-19T10:00:00",
          "2022-07-19T11:00:00",
          "2022-07-19T12:00:00",
          "2022-07-19T13:00:00",
          "2022-07-19T14:00:00",
          "2022-07-19T15:00:00",
          "2022-07-19T16:00:00",
          "2022-07-19T17:00:00",
          "2022-07-19T18:00:00",
          "2022-07-19T19:00:00",
          "2022-07-19T20:00:00",
          "2022-07-19T21:00:00",
          "2022-07-19T22:00:00",
          "2022-07-19T23:00:00",
          "2022-07-20T00:00:00",
          "2022-07-20T01:00:00",
          "2022-07-20T02:00:00",
          "2022-07-20T03:00:00",
          "2022-07-20T04:00:00",
          "2022-07-20T05:00:00",
          "2022-07-20T06:00:00",
          "2022-07-20T07:00:00",
          "2022-07-20T08:00:00",
          "2022-07-20T09:00:00",
          "2022-07-20T10:00:00",
          "2022-07-20T11:00:00",
          "2022-07-20T12:00:00",
          "2022-07-20T13:00:00",
          "2022-07-20T14:00:00",
          "2022-07-20T15:00:00",
          "2022-07-20T16:00:00",
          "2022-07-20T17:00:00",
          "2022-07-20T18:00:00",
          "2022-07-20T19:00:00",
          "2022-07-20T20:00:00",
          "2022-07-20T21:00:00",
          "2022-07-20T22:00:00",
          "2022-07-20T23:00:00",
          "2022-07-21T00:00:00",
          "2022-07-21T01:00:00",
          "2022-07-21T02:00:00",
          "2022-07-21T03:00:00",
          "2022-07-21T04:00:00",
          "2022-07-21T05:00:00",
          "2022-07-21T06:00:00",
          "2022-07-21T07:00:00",
          "2022-07-21T08:00:00",
          "2022-07-21T09:00:00",
          "2022-07-21T10:00:00",
          "2022-07-21T11:00:00",
          "2022-07-21T12:00:00",
          "2022-07-21T13:00:00",
          "2022-07-21T14:00:00",
          "2022-07-21T15:00:00",
          "2022-07-21T16:00:00",
          "2022-07-21T17:00:00",
          "2022-07-21T18:00:00",
          "2022-07-21T19:00:00",
          "2022-07-21T20:00:00",
          "2022-07-21T21:00:00",
          "2022-07-21T22:00:00",
          "2022-07-21T23:00:00",
          "2022-07-22T00:00:00",
          "2022-07-22T01:00:00",
          "2022-07-22T02:00:00",
          "2022-07-22T03:00:00",
          "2022-07-22T04:00:00",
          "2022-07-22T05:00:00",
          "2022-07-22T06:00:00",
          "2022-07-22T07:00:00",
          "2022-07-22T08:00:00",
          "2022-07-22T09:00:00",
          "2022-07-22T10:00:00",
          "2022-07-22T11:00:00",
          "2022-07-22T12:00:00",
          "2022-07-22T13:00:00",
          "2022-07-22T14:00:00",
          "2022-07-22T15:00:00",
          "2022-07-22T16:00:00",
          "2022-07-22T17:00:00",
          "2022-07-22T18:00:00",
          "2022-07-22T19:00:00",
          "2022-07-22T20:00:00",
          "2022-07-22T21:00:00",
          "2022-07-22T22:00:00",
          "2022-07-22T23:00:00",
          "2022-07-23T00:00:00",
          "2022-07-23T01:00:00",
          "2022-07-23T02:00:00",
          "2022-07-23T03:00:00",
          "2022-07-23T04:00:00",
          "2022-07-23T05:00:00",
          "2022-07-23T06:00:00",
          "2022-07-23T07:00:00",
          "2022-07-23T08:00:00",
          "2022-07-23T09:00:00",
          "2022-07-23T10:00:00",
          "2022-07-23T11:00:00",
          "2022-07-23T12:00:00",
          "2022-07-23T13:00:00",
          "2022-07-23T14:00:00",
          "2022-07-23T15:00:00",
          "2022-07-23T16:00:00",
          "2022-07-23T17:00:00",
          "2022-07-23T18:00:00",
          "2022-07-23T19:00:00",
          "2022-07-23T20:00:00",
          "2022-07-23T21:00:00",
          "2022-07-23T22:00:00",
          "2022-07-23T23:00:00",
          "2022-07-24T00:00:00",
          "2022-07-24T01:00:00",
          "2022-07-24T02:00:00",
          "2022-07-24T03:00:00",
          "2022-07-24T04:00:00",
          "2022-07-24T05:00:00",
          "2022-07-24T06:00:00",
          "2022-07-24T07:00:00",
          "2022-07-24T08:00:00",
          "2022-07-24T09:00:00",
          "2022-07-24T10:00:00",
          "2022-07-24T11:00:00",
          "2022-07-24T12:00:00",
          "2022-07-24T13:00:00",
          "2022-07-24T14:00:00",
          "2022-07-24T15:00:00",
          "2022-07-24T16:00:00",
          "2022-07-24T17:00:00",
          "2022-07-24T18:00:00",
          "2022-07-24T19:00:00",
          "2022-07-24T20:00:00",
          "2022-07-24T21:00:00",
          "2022-07-24T22:00:00",
          "2022-07-24T23:00:00",
          "2022-07-25T00:00:00",
          "2022-07-25T01:00:00",
          "2022-07-25T02:00:00",
          "2022-07-25T03:00:00",
          "2022-07-25T04:00:00",
          "2022-07-25T05:00:00",
          "2022-07-25T06:00:00",
          "2022-07-25T07:00:00",
          "2022-07-25T08:00:00",
          "2022-07-25T09:00:00",
          "2022-07-25T10:00:00",
          "2022-07-25T11:00:00",
          "2022-07-25T12:00:00",
          "2022-07-25T13:00:00",
          "2022-07-25T14:00:00",
          "2022-07-25T15:00:00",
          "2022-07-25T16:00:00",
          "2022-07-25T17:00:00",
          "2022-07-25T18:00:00",
          "2022-07-25T19:00:00",
          "2022-07-25T20:00:00",
          "2022-07-25T21:00:00",
          "2022-07-25T22:00:00",
          "2022-07-25T23:00:00",
          "2022-07-26T00:00:00",
          "2022-07-26T01:00:00",
          "2022-07-26T02:00:00",
          "2022-07-26T03:00:00",
          "2022-07-26T04:00:00",
          "2022-07-26T05:00:00",
          "2022-07-26T06:00:00",
          "2022-07-26T07:00:00",
          "2022-07-26T08:00:00",
          "2022-07-26T09:00:00",
          "2022-07-26T10:00:00",
          "2022-07-26T11:00:00",
          "2022-07-26T12:00:00",
          "2022-07-26T13:00:00",
          "2022-07-26T14:00:00",
          "2022-07-26T15:00:00",
          "2022-07-26T16:00:00",
          "2022-07-26T17:00:00",
          "2022-07-26T18:00:00",
          "2022-07-26T19:00:00",
          "2022-07-26T20:00:00",
          "2022-07-26T21:00:00",
          "2022-07-26T22:00:00",
          "2022-07-26T23:00:00",
          "2022-07-27T00:00:00",
          "2022-07-27T01:00:00",
          "2022-07-27T02:00:00",
          "2022-07-27T03:00:00",
          "2022-07-27T04:00:00",
          "2022-07-27T05:00:00",
          "2022-07-27T06:00:00",
          "2022-07-27T07:00:00",
          "2022-07-27T08:00:00",
          "2022-07-27T09:00:00",
          "2022-07-27T10:00:00",
          "2022-07-27T11:00:00",
          "2022-07-27T12:00:00",
          "2022-07-27T13:00:00",
          "2022-07-27T14:00:00",
          "2022-07-27T15:00:00",
          "2022-07-27T16:00:00",
          "2022-07-27T17:00:00",
          "2022-07-27T18:00:00",
          "2022-07-27T19:00:00",
          "2022-07-27T20:00:00",
          "2022-07-27T21:00:00",
          "2022-07-27T22:00:00",
          "2022-07-27T23:00:00",
          "2022-07-28T00:00:00",
          "2022-07-28T01:00:00",
          "2022-07-28T02:00:00",
          "2022-07-28T03:00:00",
          "2022-07-28T04:00:00",
          "2022-07-28T05:00:00",
          "2022-07-28T06:00:00",
          "2022-07-28T07:00:00",
          "2022-07-28T08:00:00",
          "2022-07-28T09:00:00",
          "2022-07-28T10:00:00",
          "2022-07-28T11:00:00",
          "2022-07-28T12:00:00",
          "2022-07-28T13:00:00",
          "2022-07-28T14:00:00",
          "2022-07-28T15:00:00",
          "2022-07-28T16:00:00",
          "2022-07-28T17:00:00",
          "2022-07-28T18:00:00",
          "2022-07-28T19:00:00",
          "2022-07-28T20:00:00",
          "2022-07-28T21:00:00",
          "2022-07-28T22:00:00",
          "2022-07-28T23:00:00",
          "2022-07-29T00:00:00",
          "2022-07-29T01:00:00",
          "2022-07-29T02:00:00",
          "2022-07-29T03:00:00",
          "2022-07-29T04:00:00",
          "2022-07-29T05:00:00",
          "2022-07-29T06:00:00",
          "2022-07-29T07:00:00",
          "2022-07-29T08:00:00",
          "2022-07-29T09:00:00",
          "2022-07-29T10:00:00",
          "2022-07-29T11:00:00",
          "2022-07-29T12:00:00",
          "2022-07-29T13:00:00",
          "2022-07-29T14:00:00",
          "2022-07-29T15:00:00",
          "2022-07-29T16:00:00",
          "2022-07-29T17:00:00",
          "2022-07-29T18:00:00",
          "2022-07-29T19:00:00",
          "2022-07-29T20:00:00",
          "2022-07-29T21:00:00",
          "2022-07-29T22:00:00",
          "2022-07-29T23:00:00",
          "2022-07-30T00:00:00",
          "2022-07-30T01:00:00",
          "2022-07-30T02:00:00",
          "2022-07-30T03:00:00",
          "2022-07-30T04:00:00",
          "2022-07-30T05:00:00",
          "2022-07-30T06:00:00",
          "2022-07-30T07:00:00",
          "2022-07-30T08:00:00",
          "2022-07-30T09:00:00",
          "2022-07-30T10:00:00",
          "2022-07-30T11:00:00",
          "2022-07-30T12:00:00",
          "2022-07-30T13:00:00",
          "2022-07-30T14:00:00",
          "2022-07-30T15:00:00",
          "2022-07-30T16:00:00",
          "2022-07-30T17:00:00",
          "2022-07-30T18:00:00",
          "2022-07-30T19:00:00",
          "2022-07-30T20:00:00",
          "2022-07-30T21:00:00",
          "2022-07-30T22:00:00",
          "2022-07-30T23:00:00",
          "2022-07-31T00:00:00",
          "2022-07-31T01:00:00",
          "2022-07-31T02:00:00",
          "2022-07-31T03:00:00",
          "2022-07-31T04:00:00",
          "2022-07-31T05:00:00",
          "2022-07-31T06:00:00",
          "2022-07-31T07:00:00",
          "2022-07-31T08:00:00",
          "2022-07-31T09:00:00",
          "2022-07-31T10:00:00",
          "2022-07-31T11:00:00",
          "2022-07-31T12:00:00",
          "2022-07-31T13:00:00",
          "2022-07-31T14:00:00",
          "2022-07-31T15:00:00",
          "2022-07-31T16:00:00",
          "2022-07-31T17:00:00",
          "2022-07-31T18:00:00",
          "2022-07-31T19:00:00",
          "2022-07-31T20:00:00",
          "2022-07-31T21:00:00",
          "2022-07-31T22:00:00",
          "2022-07-31T23:00:00",
          "2022-08-01T00:00:00",
          "2022-08-01T01:00:00",
          "2022-08-01T02:00:00",
          "2022-08-01T03:00:00",
          "2022-08-01T04:00:00",
          "2022-08-01T05:00:00",
          "2022-08-01T06:00:00",
          "2022-08-01T07:00:00",
          "2022-08-01T08:00:00",
          "2022-08-01T09:00:00",
          "2022-08-01T10:00:00",
          "2022-08-01T11:00:00",
          "2022-08-01T12:00:00",
          "2022-08-01T13:00:00",
          "2022-08-01T14:00:00",
          "2022-08-01T15:00:00",
          "2022-08-01T16:00:00",
          "2022-08-01T17:00:00",
          "2022-08-01T18:00:00",
          "2022-08-01T19:00:00",
          "2022-08-01T20:00:00",
          "2022-08-01T21:00:00",
          "2022-08-01T22:00:00",
          "2022-08-01T23:00:00",
          "2022-08-02T00:00:00",
          "2022-08-02T01:00:00",
          "2022-08-02T02:00:00",
          "2022-08-02T03:00:00",
          "2022-08-02T04:00:00",
          "2022-08-02T05:00:00",
          "2022-08-02T06:00:00",
          "2022-08-02T07:00:00",
          "2022-08-02T08:00:00",
          "2022-08-02T09:00:00",
          "2022-08-02T10:00:00",
          "2022-08-02T11:00:00",
          "2022-08-02T12:00:00",
          "2022-08-02T13:00:00",
          "2022-08-02T14:00:00",
          "2022-08-02T15:00:00",
          "2022-08-02T16:00:00",
          "2022-08-02T17:00:00",
          "2022-08-02T18:00:00",
          "2022-08-02T19:00:00",
          "2022-08-02T20:00:00",
          "2022-08-02T21:00:00",
          "2022-08-02T22:00:00",
          "2022-08-02T23:00:00",
          "2022-08-03T00:00:00",
          "2022-08-03T01:00:00",
          "2022-08-03T02:00:00",
          "2022-08-03T03:00:00",
          "2022-08-03T04:00:00",
          "2022-08-03T05:00:00",
          "2022-08-03T06:00:00",
          "2022-08-03T07:00:00",
          "2022-08-03T08:00:00",
          "2022-08-03T09:00:00",
          "2022-08-03T10:00:00",
          "2022-08-03T11:00:00",
          "2022-08-03T12:00:00",
          "2022-08-03T13:00:00",
          "2022-08-03T14:00:00",
          "2022-08-03T15:00:00",
          "2022-08-03T16:00:00",
          "2022-08-03T17:00:00",
          "2022-08-03T18:00:00",
          "2022-08-03T19:00:00",
          "2022-08-03T20:00:00",
          "2022-08-03T21:00:00",
          "2022-08-03T22:00:00",
          "2022-08-03T23:00:00",
          "2022-08-04T00:00:00",
          "2022-08-04T01:00:00",
          "2022-08-04T02:00:00",
          "2022-08-04T03:00:00",
          "2022-08-04T04:00:00",
          "2022-08-04T05:00:00",
          "2022-08-04T06:00:00",
          "2022-08-04T07:00:00",
          "2022-08-04T08:00:00",
          "2022-08-04T09:00:00",
          "2022-08-04T10:00:00",
          "2022-08-04T11:00:00",
          "2022-08-04T12:00:00",
          "2022-08-04T13:00:00",
          "2022-08-04T14:00:00",
          "2022-08-04T15:00:00",
          "2022-08-04T16:00:00",
          "2022-08-04T17:00:00",
          "2022-08-04T18:00:00",
          "2022-08-04T19:00:00",
          "2022-08-04T20:00:00",
          "2022-08-04T21:00:00",
          "2022-08-04T22:00:00",
          "2022-08-04T23:00:00",
          "2022-08-05T00:00:00",
          "2022-08-05T01:00:00",
          "2022-08-05T02:00:00",
          "2022-08-05T03:00:00",
          "2022-08-05T04:00:00",
          "2022-08-05T05:00:00",
          "2022-08-05T06:00:00",
          "2022-08-05T07:00:00",
          "2022-08-05T08:00:00",
          "2022-08-05T09:00:00",
          "2022-08-05T10:00:00",
          "2022-08-05T11:00:00",
          "2022-08-05T12:00:00",
          "2022-08-05T13:00:00",
          "2022-08-05T14:00:00",
          "2022-08-05T15:00:00",
          "2022-08-05T16:00:00",
          "2022-08-05T17:00:00",
          "2022-08-05T18:00:00",
          "2022-08-05T19:00:00",
          "2022-08-05T20:00:00",
          "2022-08-05T21:00:00",
          "2022-08-05T22:00:00",
          "2022-08-05T23:00:00",
          "2022-08-06T00:00:00",
          "2022-08-06T01:00:00",
          "2022-08-06T02:00:00",
          "2022-08-06T03:00:00",
          "2022-08-06T04:00:00",
          "2022-08-06T05:00:00",
          "2022-08-06T06:00:00",
          "2022-08-06T07:00:00",
          "2022-08-06T08:00:00",
          "2022-08-06T09:00:00",
          "2022-08-06T10:00:00",
          "2022-08-06T11:00:00",
          "2022-08-06T12:00:00",
          "2022-08-06T13:00:00",
          "2022-08-06T14:00:00",
          "2022-08-06T15:00:00",
          "2022-08-06T16:00:00",
          "2022-08-06T17:00:00",
          "2022-08-06T18:00:00",
          "2022-08-06T19:00:00",
          "2022-08-06T20:00:00",
          "2022-08-06T21:00:00",
          "2022-08-06T22:00:00",
          "2022-08-06T23:00:00",
          "2022-08-07T00:00:00",
          "2022-08-07T01:00:00",
          "2022-08-07T02:00:00",
          "2022-08-07T03:00:00",
          "2022-08-07T04:00:00",
          "2022-08-07T05:00:00",
          "2022-08-07T06:00:00",
          "2022-08-07T07:00:00",
          "2022-08-07T08:00:00",
          "2022-08-07T09:00:00",
          "2022-08-07T10:00:00",
          "2022-08-07T11:00:00",
          "2022-08-07T12:00:00",
          "2022-08-07T13:00:00",
          "2022-08-07T14:00:00",
          "2022-08-07T15:00:00",
          "2022-08-07T16:00:00",
          "2022-08-07T17:00:00",
          "2022-08-07T18:00:00",
          "2022-08-07T19:00:00",
          "2022-08-07T20:00:00",
          "2022-08-07T21:00:00",
          "2022-08-07T22:00:00",
          "2022-08-07T23:00:00",
          "2022-08-08T00:00:00",
          "2022-08-08T01:00:00",
          "2022-08-08T02:00:00",
          "2022-08-08T03:00:00",
          "2022-08-08T04:00:00",
          "2022-08-08T05:00:00",
          "2022-08-08T06:00:00",
          "2022-08-08T07:00:00",
          "2022-08-08T08:00:00",
          "2022-08-08T09:00:00",
          "2022-08-08T10:00:00",
          "2022-08-08T11:00:00",
          "2022-08-08T12:00:00",
          "2022-08-08T13:00:00",
          "2022-08-08T14:00:00",
          "2022-08-08T15:00:00",
          "2022-08-08T16:00:00",
          "2022-08-08T17:00:00",
          "2022-08-08T18:00:00",
          "2022-08-08T19:00:00",
          "2022-08-08T20:00:00",
          "2022-08-08T21:00:00",
          "2022-08-08T22:00:00",
          "2022-08-08T23:00:00",
          "2022-08-09T00:00:00",
          "2022-08-09T01:00:00",
          "2022-08-09T02:00:00",
          "2022-08-09T03:00:00",
          "2022-08-09T04:00:00",
          "2022-08-09T05:00:00",
          "2022-08-09T06:00:00",
          "2022-08-09T07:00:00",
          "2022-08-09T08:00:00",
          "2022-08-09T09:00:00",
          "2022-08-09T10:00:00",
          "2022-08-09T11:00:00",
          "2022-08-09T12:00:00",
          "2022-08-09T13:00:00",
          "2022-08-09T14:00:00",
          "2022-08-09T15:00:00",
          "2022-08-09T16:00:00",
          "2022-08-09T17:00:00",
          "2022-08-09T18:00:00",
          "2022-08-09T19:00:00",
          "2022-08-09T20:00:00",
          "2022-08-09T21:00:00",
          "2022-08-09T22:00:00",
          "2022-08-09T23:00:00",
          "2022-08-10T00:00:00",
          "2022-08-10T01:00:00",
          "2022-08-10T02:00:00",
          "2022-08-10T03:00:00",
          "2022-08-10T04:00:00",
          "2022-08-10T05:00:00",
          "2022-08-10T06:00:00",
          "2022-08-10T07:00:00",
          "2022-08-10T08:00:00",
          "2022-08-10T09:00:00",
          "2022-08-10T10:00:00",
          "2022-08-10T11:00:00",
          "2022-08-10T12:00:00",
          "2022-08-10T13:00:00",
          "2022-08-10T14:00:00",
          "2022-08-10T15:00:00",
          "2022-08-10T16:00:00",
          "2022-08-10T17:00:00",
          "2022-08-10T18:00:00",
          "2022-08-10T19:00:00",
          "2022-08-10T20:00:00",
          "2022-08-10T21:00:00",
          "2022-08-10T22:00:00",
          "2022-08-10T23:00:00",
          "2022-08-11T00:00:00",
          "2022-08-11T01:00:00",
          "2022-08-11T02:00:00",
          "2022-08-11T03:00:00",
          "2022-08-11T04:00:00",
          "2022-08-11T05:00:00",
          "2022-08-11T06:00:00",
          "2022-08-11T07:00:00",
          "2022-08-11T08:00:00",
          "2022-08-11T09:00:00",
          "2022-08-11T10:00:00",
          "2022-08-11T11:00:00",
          "2022-08-11T12:00:00",
          "2022-08-11T13:00:00",
          "2022-08-11T14:00:00",
          "2022-08-11T15:00:00",
          "2022-08-11T16:00:00",
          "2022-08-11T17:00:00",
          "2022-08-11T18:00:00",
          "2022-08-11T19:00:00",
          "2022-08-11T20:00:00",
          "2022-08-11T21:00:00",
          "2022-08-11T22:00:00",
          "2022-08-11T23:00:00",
          "2022-08-12T00:00:00",
          "2022-08-12T01:00:00",
          "2022-08-12T02:00:00",
          "2022-08-12T03:00:00",
          "2022-08-12T04:00:00",
          "2022-08-12T05:00:00",
          "2022-08-12T06:00:00",
          "2022-08-12T07:00:00",
          "2022-08-12T08:00:00",
          "2022-08-12T09:00:00",
          "2022-08-12T10:00:00",
          "2022-08-12T11:00:00",
          "2022-08-12T12:00:00",
          "2022-08-12T13:00:00",
          "2022-08-12T14:00:00",
          "2022-08-12T15:00:00",
          "2022-08-12T16:00:00",
          "2022-08-12T17:00:00",
          "2022-08-12T18:00:00",
          "2022-08-12T19:00:00",
          "2022-08-12T20:00:00",
          "2022-08-12T21:00:00",
          "2022-08-12T22:00:00",
          "2022-08-12T23:00:00",
          "2022-08-13T00:00:00",
          "2022-08-13T01:00:00",
          "2022-08-13T02:00:00",
          "2022-08-13T03:00:00",
          "2022-08-13T04:00:00",
          "2022-08-13T05:00:00",
          "2022-08-13T06:00:00",
          "2022-08-13T07:00:00",
          "2022-08-13T08:00:00",
          "2022-08-13T09:00:00",
          "2022-08-13T10:00:00",
          "2022-08-13T11:00:00",
          "2022-08-13T12:00:00",
          "2022-08-13T13:00:00",
          "2022-08-13T14:00:00",
          "2022-08-13T15:00:00",
          "2022-08-13T16:00:00",
          "2022-08-13T17:00:00",
          "2022-08-13T18:00:00",
          "2022-08-13T19:00:00",
          "2022-08-13T20:00:00",
          "2022-08-13T21:00:00",
          "2022-08-13T22:00:00",
          "2022-08-13T23:00:00"
         ],
         "xaxis": "x",
         "y": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          3,
          0,
          0,
          3,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          2,
          1,
          1,
          9,
          4,
          4,
          6,
          2,
          4,
          5,
          2,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          3,
          0,
          1,
          4,
          2,
          4,
          5,
          3,
          2,
          4,
          2,
          5,
          2,
          3,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          3,
          3,
          1,
          4,
          7,
          5,
          7,
          3,
          2,
          5,
          4,
          3,
          0,
          1,
          1,
          1,
          4,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          5,
          1,
          3,
          0,
          8,
          1,
          5,
          1,
          7,
          4,
          1,
          4,
          2,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          3,
          1,
          1,
          2,
          1,
          0,
          5,
          5,
          0,
          4,
          1,
          2,
          3,
          3,
          1,
          2,
          0,
          1,
          0,
          0,
          0,
          2,
          0,
          0,
          0,
          2,
          1,
          0,
          0,
          1,
          0,
          4,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          2,
          0,
          0,
          2,
          0,
          2,
          3,
          3,
          4,
          0,
          6,
          4,
          1,
          1,
          1,
          0,
          0,
          2,
          1,
          0,
          0,
          1,
          0,
          1,
          2,
          2,
          1,
          0,
          3,
          4,
          3,
          2,
          2,
          1,
          2,
          7,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          3,
          3,
          0,
          2,
          3,
          0,
          2,
          2,
          2,
          5,
          4,
          4,
          2,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          2,
          1,
          4,
          3,
          4,
          2,
          5,
          3,
          0,
          1,
          2,
          2,
          3,
          2,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          2,
          2,
          1,
          2,
          2,
          3,
          1,
          5,
          3,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          2,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          2,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          2,
          0,
          0,
          4,
          0,
          2,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          5,
          3,
          4,
          1,
          4,
          7,
          8,
          8,
          2,
          3,
          5,
          5,
          5,
          5,
          1,
          0,
          1,
          0,
          3,
          0,
          0,
          1,
          0,
          2,
          3,
          5,
          2,
          4,
          2,
          5,
          7,
          7,
          9,
          6,
          1,
          2,
          2,
          0,
          0,
          2,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          3,
          5,
          2,
          3,
          4,
          7,
          9,
          4,
          3,
          5,
          4,
          3,
          1,
          1,
          4,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          3,
          3,
          1,
          5,
          2,
          3,
          3,
          7,
          6,
          7,
          5,
          6,
          4,
          4,
          3,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          2,
          2,
          4,
          2,
          8,
          1,
          9,
          5,
          5,
          5,
          3,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          2,
          1,
          2,
          4,
          2,
          0,
          2,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          2,
          0,
          0,
          3,
          0,
          0,
          1,
          0,
          0,
          3,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          3,
          4,
          2,
          2,
          6,
          4,
          2,
          9,
          6,
          5,
          5,
          2,
          3,
          5,
          2,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          3,
          5,
          0,
          7,
          5,
          10,
          7,
          9,
          5,
          4,
          9,
          1,
          3,
          2,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          4,
          5,
          3,
          3,
          6,
          4,
          4,
          13,
          8,
          9,
          5,
          11,
          4,
          3,
          1,
          2,
          2,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          6,
          7,
          3,
          0,
          5,
          5,
          9,
          7,
          5,
          7,
          1,
          8,
          2,
          3,
          2,
          3,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          2,
          6,
          5,
          0,
          3,
          7,
          4,
          9,
          9,
          8,
          4,
          4,
          1,
          5,
          6,
          2,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          2,
          4,
          0,
          1,
          1,
          1,
          0,
          2,
          2,
          0,
          0,
          1,
          0,
          0
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "x=%{x}<br>y=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "green",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "2022-08-14T00:00:00",
          "2022-08-14T01:00:00",
          "2022-08-14T02:00:00",
          "2022-08-14T03:00:00",
          "2022-08-14T04:00:00",
          "2022-08-14T05:00:00",
          "2022-08-14T06:00:00",
          "2022-08-14T07:00:00",
          "2022-08-14T08:00:00",
          "2022-08-14T09:00:00",
          "2022-08-14T10:00:00",
          "2022-08-14T11:00:00",
          "2022-08-14T12:00:00",
          "2022-08-14T13:00:00",
          "2022-08-14T14:00:00",
          "2022-08-14T15:00:00",
          "2022-08-14T16:00:00",
          "2022-08-14T17:00:00",
          "2022-08-14T18:00:00",
          "2022-08-14T19:00:00",
          "2022-08-14T20:00:00",
          "2022-08-14T21:00:00",
          "2022-08-14T22:00:00",
          "2022-08-14T23:00:00",
          "2022-08-15T00:00:00",
          "2022-08-15T01:00:00",
          "2022-08-15T02:00:00",
          "2022-08-15T03:00:00",
          "2022-08-15T04:00:00",
          "2022-08-15T05:00:00",
          "2022-08-15T06:00:00",
          "2022-08-15T07:00:00",
          "2022-08-15T08:00:00",
          "2022-08-15T09:00:00",
          "2022-08-15T10:00:00",
          "2022-08-15T11:00:00"
         ],
         "xaxis": "x",
         "y": [
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          2,
          1,
          0,
          1,
          1,
          8,
          3,
          0,
          0,
          2,
          0,
          0,
          0,
          1,
          0,
          0,
          2,
          0,
          2,
          0,
          0,
          1,
          0,
          0,
          4
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "x=%{x}<br>y=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "red",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "2022-08-14T00:00:00",
          "2022-08-14T01:00:00",
          "2022-08-14T02:00:00",
          "2022-08-14T03:00:00",
          "2022-08-14T04:00:00",
          "2022-08-14T05:00:00",
          "2022-08-14T06:00:00",
          "2022-08-14T07:00:00",
          "2022-08-14T08:00:00",
          "2022-08-14T09:00:00",
          "2022-08-14T10:00:00",
          "2022-08-14T11:00:00",
          "2022-08-14T12:00:00",
          "2022-08-14T13:00:00",
          "2022-08-14T14:00:00",
          "2022-08-14T15:00:00",
          "2022-08-14T16:00:00",
          "2022-08-14T17:00:00",
          "2022-08-14T18:00:00",
          "2022-08-14T19:00:00",
          "2022-08-14T20:00:00",
          "2022-08-14T21:00:00",
          "2022-08-14T22:00:00",
          "2022-08-14T23:00:00",
          "2022-08-15T00:00:00",
          "2022-08-15T01:00:00",
          "2022-08-15T02:00:00",
          "2022-08-15T03:00:00",
          "2022-08-15T04:00:00",
          "2022-08-15T05:00:00",
          "2022-08-15T06:00:00",
          "2022-08-15T07:00:00",
          "2022-08-15T08:00:00",
          "2022-08-15T09:00:00",
          "2022-08-15T10:00:00",
          "2022-08-15T11:00:00"
         ],
         "xaxis": "x",
         "y": [
          0.2677842528683347,
          0.30961694969857423,
          0.05049496027962262,
          0.12114732466526662,
          0.15768517148477804,
          0.26827909613502127,
          0.0565681759143973,
          0.05656774041424805,
          0.02609783873707163,
          0.17839883839651208,
          0.43271683406799316,
          0.1877074418519697,
          0.8277902195333872,
          0.8533561930068977,
          1.1663953483442142,
          1.2186958573784576,
          1.5621154424270316,
          0.534872830010324,
          0.6102185418134475,
          0.7904644690764228,
          0.5289406267946941,
          0.4062264866718956,
          0.43771573411510584,
          0.27097679971194694,
          0.18396518933992714,
          0.280361636820789,
          0.3251331798862315,
          0.03988891840211399,
          0.09208586137207565,
          0.16974514294355458,
          0.32444414753330203,
          1.3831438313811475,
          3.4249537257843716,
          2.2100743918745547,
          2.212995805769024,
          3.02826385900396
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Pick up hour=2022-08-14 00:00:00, location_id=33"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.plot import plot_one_sample\n",
    "\n",
    "plot_one_sample(\n",
    "    features=X_test,\n",
    "    targets=y_test,\n",
    "    example_id=500,\n",
    "    predictions=pd.DataFrame(predictions)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b98d97558a062384a76b0309256306c9ce5dd4e2074fe66c33532239207fc923"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
